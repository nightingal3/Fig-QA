{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADA_FINETUNED = 'ada:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-03-10-25'\n",
    "BABBAGE_FINETUNED = 'babbage:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-04-06-02'\n",
    "CURIE_FINETUNED = 'curie:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-04-35-14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(l):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "def sentence_prob(xiyi, normalize=False, until_first_period=False):\n",
    "    fn = avg if normalize else sum\n",
    "    end_idx = xiyi['tokens'].index(\".\")+1 if until_first_period else len(xiyi['token_logprobs'])\n",
    "    \n",
    "    return math.exp(fn(xiyi['token_logprobs'][1:end_idx]))\n",
    "\n",
    "def generate_probability_csv(model_name, split='test'):\n",
    "    fname = f\"{split}_logprobs_{model_name}.json\"\n",
    "    with open(fname) as f:\n",
    "        logprobs = json.load(f)\n",
    "    fname_ending = f\"{split}_logprobs_endings_{model_name}.json\"\n",
    "    with open(fname_ending) as f:\n",
    "        logprobs_ending = json.load(f)\n",
    "\n",
    "    qids = list({k.split('_')[0] for k in logprobs.keys()})\n",
    "    columns = [\"x_1\",\"x_2\",\"y_1\",\"y_2\",\"P(x_1, y_1)\",\"P(x_1, y_2)\",\"P(x_2, y_1)\",\"P(x_2, y_2)\",\n",
    "               \"P(x_1)\", \"P(x_2)\", \"P(y_1)\", \"P(y_2)\",\n",
    "               \"P(y_1|x_1)\",\"P(y_2|x_2)\",\"P(x_1|y_1)\",\"P(x_2|y_2)\"]\n",
    "    csv_lines = []\n",
    "\n",
    "    for qid in qids:\n",
    "#         if qid == '1368': continue \n",
    "        try:\n",
    "            x1y1, x1y2 = logprobs[f\"{qid}_0\"]\n",
    "            x2y1, x2y2 = logprobs[f\"{qid}_1\"]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        y1, y2 = logprobs_ending[qid]\n",
    "\n",
    "        x1_text, y1_text = ''.join(x1y1['tokens']).split('. ', maxsplit=1)\n",
    "        x2_text, y2_text = ''.join(x2y2['tokens']).split('. ', maxsplit=1)\n",
    "\n",
    "        x1y1_prob = sentence_prob(x1y1, normalize=True)\n",
    "        x1y2_prob = sentence_prob(x1y2, normalize=True)\n",
    "        x2y1_prob = sentence_prob(x2y1, normalize=True)\n",
    "        x2y2_prob = sentence_prob(x2y2, normalize=True)\n",
    "        x1_prob = sentence_prob(x1y1, normalize=True, until_first_period=True)\n",
    "        x2_prob = sentence_prob(x2y2, normalize=True, until_first_period=True)\n",
    "        y1_prob = sentence_prob(y1, normalize=True)\n",
    "        y2_prob = sentence_prob(y2, normalize=True)\n",
    "        csv_lines.append([x1_text, x2_text, y1_text, y2_text, x1y1_prob, x1y2_prob, x2y1_prob, x2y2_prob,\n",
    "                         x1_prob, x2_prob, y1_prob, y2_prob])\n",
    "\n",
    "    df = pd.DataFrame(csv_lines, columns=columns[:12])\n",
    "    df[\"P(y_1|x_1)\"] = df[\"P(x_1, y_1)\"] / (df[\"P(x_1, y_1)\"] + df[\"P(x_1, y_2)\"])\n",
    "    df[\"P(y_2|x_2)\"] = df[\"P(x_2, y_2)\"] / (df[\"P(x_2, y_2)\"] + df[\"P(x_2, y_1)\"])\n",
    "    df[\"P(x_1|y_1)\"] = df[\"P(x_1, y_1)\"] / (df[\"P(x_1, y_1)\"] + df[\"P(x_2, y_1)\"])\n",
    "    df[\"P(x_2|y_2)\"] = df[\"P(x_2, y_2)\"] / (df[\"P(x_2, y_2)\"] + df[\"P(x_1, y_2)\"])\n",
    "    if 'ft-user' in model_name:\n",
    "        model_name = 'finedtuned_' + model_name.split(':')[0]\n",
    "    df.to_csv(f\"gpt3_probabilities_{model_name}_test_morecolumns.csv\", index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_probability_csv(CURIE_FINETUNED, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward accuracy\n",
      "0.6448516579406631\n"
     ]
    }
   ],
   "source": [
    "print('forward accuracy')\n",
    "print(avg((len(df[df[\"P(y_1|x_1)\"]>0.5])/len(df), len(df[df[\"P(y_2|x_2)\"]>0.5])/len(df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backward accuracy\n",
      "0.5846422338568935\n"
     ]
    }
   ],
   "source": [
    "print('backward accuracy')\n",
    "print(avg((len(df[df[\"P(x_1|y_1)\"]>0.5])/len(df), len(df[df[\"P(x_2|y_2)\"]>0.5])/len(df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2811109223052686e-11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(sum(x1y1['token_logprobs'][1:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
