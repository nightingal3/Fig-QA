{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "openai.api_key = open(\"openai_api.key\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(sent):\n",
    "    if not sent.endswith(\".\") or sent.endswith(\"!\"):  # finish with period\n",
    "        sent += '.'\n",
    "    if not sent[0].isupper():  # start with a capital letter\n",
    "        sent = sent[0].upper() + sent[1:]\n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HITId</th>\n",
       "      <th>AssignmentId</th>\n",
       "      <th>startphrase</th>\n",
       "      <th>ending1</th>\n",
       "      <th>ending2</th>\n",
       "      <th>labels</th>\n",
       "      <th>valid</th>\n",
       "      <th>qid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3YCT0L9OMMJ03QGXPN8IR4I5IX0SN8</td>\n",
       "      <td>3LOTDFNYA89K9ZIJ16484885K8ZFWO</td>\n",
       "      <td>The girl had the flightiness of a sparrow</td>\n",
       "      <td>The girl was very fickle.</td>\n",
       "      <td>The girl was very stable.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3YCT0L9OMMJ03QGXPN8IR4I5IX0SN8</td>\n",
       "      <td>3LOTDFNYA89K9ZIJ16484885K8ZFWO</td>\n",
       "      <td>The girl had the flightiness of a rock</td>\n",
       "      <td>The girl was very fickle.</td>\n",
       "      <td>The girl was very stable.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3YCT0L9OMMJ03QGXPN8IR4I5IX0SN8</td>\n",
       "      <td>3R6P78PK7LLYVIAKHL5FZ91IHTRTGL</td>\n",
       "      <td>It was as peaceful as a church.</td>\n",
       "      <td>It was very peaceful.</td>\n",
       "      <td>It was full of conflict and danger, not peace.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3YCT0L9OMMJ03QGXPN8IR4I5IX0SN8</td>\n",
       "      <td>3R6P78PK7LLYVIAKHL5FZ91IHTRTGL</td>\n",
       "      <td>It was as peaceful as a battlefield.</td>\n",
       "      <td>It was very peaceful.</td>\n",
       "      <td>It was full of conflict and danger, not peace.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3YCT0L9OMMJ03QGXPN8IR4I5IX0SN8</td>\n",
       "      <td>3R6P78PK7LLYVIAKHL5FZ91IHTRTGL</td>\n",
       "      <td>The leaves were as green as grass</td>\n",
       "      <td>The leaves were very green</td>\n",
       "      <td>The leaves were brown and not green at all.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            HITId                    AssignmentId  \\\n",
       "0  3YCT0L9OMMJ03QGXPN8IR4I5IX0SN8  3LOTDFNYA89K9ZIJ16484885K8ZFWO   \n",
       "1  3YCT0L9OMMJ03QGXPN8IR4I5IX0SN8  3LOTDFNYA89K9ZIJ16484885K8ZFWO   \n",
       "2  3YCT0L9OMMJ03QGXPN8IR4I5IX0SN8  3R6P78PK7LLYVIAKHL5FZ91IHTRTGL   \n",
       "3  3YCT0L9OMMJ03QGXPN8IR4I5IX0SN8  3R6P78PK7LLYVIAKHL5FZ91IHTRTGL   \n",
       "4  3YCT0L9OMMJ03QGXPN8IR4I5IX0SN8  3R6P78PK7LLYVIAKHL5FZ91IHTRTGL   \n",
       "\n",
       "                                 startphrase                     ending1  \\\n",
       "0  The girl had the flightiness of a sparrow   The girl was very fickle.   \n",
       "1     The girl had the flightiness of a rock   The girl was very fickle.   \n",
       "2            It was as peaceful as a church.       It was very peaceful.   \n",
       "3       It was as peaceful as a battlefield.       It was very peaceful.   \n",
       "4          The leaves were as green as grass  The leaves were very green   \n",
       "\n",
       "                                          ending2  labels  valid  qid  \n",
       "0                       The girl was very stable.       0      1    1  \n",
       "1                       The girl was very stable.       1      1    1  \n",
       "2  It was full of conflict and danger, not peace.       0      1    3  \n",
       "3  It was full of conflict and danger, not peace.       1      1    3  \n",
       "4     The leaves were brown and not green at all.       0      1    4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/cuichenx/Courses/11-711/A4/data/dev.csv\")\n",
    "df = df[df.valid==1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_res = {\n",
    "          \"token_logprobs\": [\n",
    "            None,\n",
    "            -8.384926,\n",
    "            -4.6257014,\n",
    "            -1.8492408,\n",
    "            -1.3289777,\n",
    "            -0.03890226,\n",
    "            -1.9416707,\n",
    "            -8.261132,\n",
    "            -0.022355538,\n",
    "            -12.232727,\n",
    "            -0.8997546,\n",
    "            -1.2286589,\n",
    "            -1.8712921,\n",
    "            -3.0148795,\n",
    "            -4.4984546,\n",
    "            -3.436775,\n",
    "            -1.384284\n",
    "          ],\n",
    "          \"tokens\": [\n",
    "            \"He\",\n",
    "            \" moves\",\n",
    "            \" at\",\n",
    "            \" the\",\n",
    "            \" speed\",\n",
    "            \" of\",\n",
    "            \" a\",\n",
    "            \" cater\",\n",
    "            \"pillar\",\n",
    "            \" pup\",\n",
    "            \"a\",\n",
    "            \".\",\n",
    "            \" He\",\n",
    "            \" moves\",\n",
    "            \" very\",\n",
    "            \" slow\",\n",
    "            \".\"\n",
    "          ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about the spend $$$ on openai API (model curie)! conitnue? [y/n]y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [05:46<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'curie'\n",
    "assert model_name in ['debug', 'ada', 'babbage', 'curie', 'davinci']\n",
    "json_lines = {}\n",
    "scores = []\n",
    "\n",
    "\n",
    "if model_name != 'debug':\n",
    "    response = input(f\"about the spend $$$ on openai API (model {model_name})! conitnue? [y/n]\")\n",
    "    if response.lower() != 'y':\n",
    "        raise Exception(\"Not continuing.\")\n",
    "else:\n",
    "    print('just debugging. this is free.')\n",
    "\n",
    "    \n",
    "for i, line in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    start = line['startphrase']\n",
    "    end1 = line['ending1']\n",
    "    end2 = line['ending2']\n",
    "    res_two_endings = []\n",
    "    for j, prompt in enumerate((\n",
    "        proc(start)+' '+proc(end1),\n",
    "        proc(start)+' '+proc(end2),\n",
    "    )):\n",
    "        if model_name == 'debug':\n",
    "            res = debug_res\n",
    "        else:\n",
    "            completion = openai.Completion.create(engine=model_name, prompt=prompt,\n",
    "                                                      max_tokens=0,\n",
    "                                                      temperature=0.0,\n",
    "                                                      logprobs=0,\n",
    "                                                      echo=True,\n",
    "                                                      n=1)\n",
    "            logprobs = completion['choices'][0]['logprobs']\n",
    "            res = {k: logprobs[k] for k in ('token_logprobs', 'tokens')}\n",
    "        res_two_endings.append(res)\n",
    "    json_lines[f\"{line.get('qid', i)}_{line['labels']}\"] = res_two_endings\n",
    "    \n",
    "    if model_name != 'debug':\n",
    "        time.sleep(0.050)  # to prevent RateLimitError\n",
    "\n",
    "fname = f\"dev_logprobs_{model_name}.json\"\n",
    "with open(fname, 'w') as f:\n",
    "    f.write('')\n",
    "\n",
    "with open(fname, 'a') as f:\n",
    "    json.dump(json_lines, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get accuracy from probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_of_ending(token_logprobs, tokens):\n",
    "    logprob_sum = 0\n",
    "    for count, (lp, t) in enumerate(zip(token_logprobs[::-1], tokens[::-1])):\n",
    "        if count > 0 and t.endswith('.'):\n",
    "            break\n",
    "        logprob_sum += lp\n",
    "    return logprob_sum / count\n",
    "\n",
    "\n",
    "def calculate_accuracy(fname):\n",
    "    with open(fname) as f:\n",
    "        logprobs = json.load(f)\n",
    "\n",
    "    correct = 0\n",
    "    for qid_label, (end1, end2) in logprobs.items():\n",
    "        end1_prob = prob_of_ending(end1['token_logprobs'], end1['tokens'])\n",
    "        end2_prob = prob_of_ending(end2['token_logprobs'], end2['tokens'])\n",
    "        label = int(qid_label[-1])\n",
    "        if (label == 0 and end1_prob > end2_prob) or (label==1 and end1_prob < end2_prob):\n",
    "            correct += 1\n",
    "\n",
    "    print(f\"correct: {correct}/{len(logprobs)} = {correct/len(logprobs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 643/1094 = 0.5877513711151737\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(\"dev_logprobs_ada.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 690/1094 = 0.6307129798903108\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(\"dev_logprobs_babbage.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 719/1094 = 0.6572212065813529\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(\"dev_logprobs_curie.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 776/1094 = 0.7093235831809872\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(\"dev_logprobs_davinci.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few shot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [00:00<00:00, 21977.59it/s]\n"
     ]
    }
   ],
   "source": [
    "prompt_bank = []\n",
    "\n",
    "for i, line in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    prompt = proc(line['startphrase']) + ' -> '\n",
    "    completion = proc(line[f'ending{line[\"labels\"]+1}'])\n",
    "    prompt_bank.append(prompt+completion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Her ego was a brick building. -> Her ego was unshakeable.\n",
      "The monkey was a 1st grade dropout. -> The monkey was dumb.\n",
      "The child was as pretty as the dog poop on my shoe. -> The child was ugly.\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(np.random.choice(prompt_bank, 3).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gpt3_few_shot(num_shots, model_name, force=False):\n",
    "    assert model_name in ['debug', 'ada', 'babbage', 'curie', 'davinci']\n",
    "    json_lines = {}\n",
    "    scores = []\n",
    "    \n",
    "    if not force:\n",
    "        if model_name != 'debug':\n",
    "            response = input(f\"about the spend $$$ on openai API (model {model_name})! conitnue? [y/n]\")\n",
    "            if response.lower() != 'y':\n",
    "                raise Exception(\"Not continuing.\")\n",
    "        else:\n",
    "            print('just debugging. this is free.')\n",
    "\n",
    "    count = 0\n",
    "    for i, line in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        start = line['startphrase']\n",
    "        end1 = line['ending1']\n",
    "        end2 = line['ending2']\n",
    "        res_two_endings = []\n",
    "        \n",
    "        if not count % 2:\n",
    "            # only update pre_propmt when i is an even number. \n",
    "            # if i is odd, use the same as the first sentence in the pair\n",
    "            pre_prompt = '\\n'.join(np.random.choice(prompt_bank, num_shots).tolist())\n",
    "        for j, ending in enumerate((end1, end2)):\n",
    "            sentence = pre_prompt + '\\n' + proc(start) + ' -> ' + proc(ending)\n",
    "\n",
    "            if model_name == 'debug':\n",
    "                print(i, '=========')\n",
    "                print(sentence)\n",
    "                res = debug_res\n",
    "            else:\n",
    "                completion = openai.Completion.create(engine=model_name, prompt=sentence,\n",
    "                                                          max_tokens=0,\n",
    "                                                          temperature=0.0,\n",
    "                                                          logprobs=0,\n",
    "                                                          echo=True,\n",
    "                                                          n=1)\n",
    "                logprobs = completion['choices'][0]['logprobs']\n",
    "                res = {k: logprobs[k] for k in ('token_logprobs', 'tokens')}\n",
    "            res_two_endings.append(res)\n",
    "        json_lines[f\"{line.get('qid', i)}_{line['labels']}\"] = res_two_endings\n",
    "\n",
    "        if model_name != 'debug':\n",
    "            time.sleep(0.05)  # to prevent RateLimitError\n",
    "        count += 1\n",
    "\n",
    "    fname = f\"dev_logprobs_{num_shots}shot_{model_name}.json\"\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write('')\n",
    "\n",
    "    with open(fname, 'a') as f:\n",
    "        json.dump(json_lines, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1094 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davinci 3 shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [08:03<00:00,  2.26it/s]\n",
      "  0%|          | 0/1094 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davinci 5 shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1094 [00:00<11:08,  1.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-32cd14f98a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'davinci'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_shots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mgpt3_few_shot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_shots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-8e6d6f0f7d4a>\u001b[0m in \u001b[0;36mgpt3_few_shot\u001b[0;34m(num_shots, model_name, force)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdebug_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 completion = openai.Completion.create(engine=model_name, prompt=sentence,\n\u001b[0m\u001b[1;32m     34\u001b[0m                                                           \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                           \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m     63\u001b[0m         )\n\u001b[1;32m     64\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mrequest_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], bool, str]:\n\u001b[0;32m---> 98\u001b[0;31m         result = self.request_raw(\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0m_thread_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             result = _thread_context.session.request(\n\u001b[0m\u001b[1;32m    256\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mabs_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# num_shots = 5  # 3, 5, 10\n",
    "# model_name = 'debug'\n",
    "\n",
    "for num_shots in (3, 5):\n",
    "    for model_name in ('debug',):\n",
    "        print(model_name, num_shots, \"shot\")\n",
    "        gpt3_few_shot(num_shots, model_name, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 639/1094 = 0.5840950639853748\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(\"dev_logprobs_3shot_ada.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 633/1094 = 0.5786106032906764\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(\"dev_logprobs_5shot_ada.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 622/1094 = 0.5685557586837294\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(\"dev_logprobs_10shot_ada.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 812/1094 = 0.7422303473491774\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(\"dev_logprobs_3shot_davinci.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get y probabilities\n",
    "probabilities of the each ending on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3_y_probs(model_name, force=False):\n",
    "    if model_name in ['debug', 'ada', 'babbage', 'curie', 'davinci']:\n",
    "        mode_kwargs = {'engine': model_name}\n",
    "    elif any(model_name.startswith(n) for n in ('ada', 'babbage', 'curie')):\n",
    "        print(\"this is a finetuned model\")\n",
    "        mode_kwargs = {'model': model_name}\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    json_lines = {}\n",
    "    scores = []\n",
    "    \n",
    "    if not force:\n",
    "        if model_name != 'debug':\n",
    "            response = input(f\"about the spend $$$ on openai API (model {model_name})! conitnue? [y/n]\")\n",
    "            if response.lower() != 'y':\n",
    "                raise Exception(\"Not continuing.\")\n",
    "        else:\n",
    "            print('just debugging. this is free.')\n",
    "\n",
    "    count = 0\n",
    "    for i, line in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        if i%2:\n",
    "            # only process even numbered lines\n",
    "            continue \n",
    "    \n",
    "        end1 = line['ending1']\n",
    "        end2 = line['ending2']\n",
    "        res_two_endings = []\n",
    "\n",
    "        for j, ending in enumerate((end1, end2)):\n",
    "            sentence = ending\n",
    "\n",
    "            if model_name == 'debug':\n",
    "                print(i, '=========')\n",
    "                print(sentence)\n",
    "                res = debug_res\n",
    "            else:\n",
    "                completion = openai.Completion.create(**mode_kwargs, prompt=sentence,\n",
    "                                                          max_tokens=0,\n",
    "                                                          temperature=0.0,\n",
    "                                                          logprobs=0,\n",
    "                                                          echo=True,\n",
    "                                                          n=1)\n",
    "                logprobs = completion['choices'][0]['logprobs']\n",
    "                res = {k: logprobs[k] for k in ('token_logprobs', 'tokens')}\n",
    "            res_two_endings.append(res)\n",
    "        json_lines[f\"{line.get('qid', i)}\"] = res_two_endings\n",
    "\n",
    "        if model_name in ['ada', 'babbage']:\n",
    "            time.sleep(0.10)  # to prevent RateLimitError\n",
    "        count += 1\n",
    "\n",
    "    fname = f\"dev_logprobs_endings_{model_name}.json\"\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write('')\n",
    "\n",
    "    with open(fname, 'a') as f:\n",
    "        json.dump(json_lines, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1094 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-03-10-25\n",
      "this is a finetuned model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [03:31<00:00,  5.16it/s]\n",
      "  0%|          | 0/1094 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babbage:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-04-06-02\n",
      "this is a finetuned model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [03:25<00:00,  5.32it/s]\n",
      "  0%|          | 0/1094 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curie:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-04-35-14\n",
      "this is a finetuned model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [03:37<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# models = ['ada', 'babbage', 'curie', 'davinci']\n",
    "ADA_FINETUNED = 'ada:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-03-10-25'\n",
    "BABBAGE_FINETUNED = 'babbage:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-04-06-02'\n",
    "CURIE_FINETUNED = 'curie:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-04-35-14'\n",
    "models = [ADA_FINETUNED, BABBAGE_FINETUNED, CURIE_FINETUNED]\n",
    "\n",
    "for m in models:\n",
    "    print(m)\n",
    "    gpt3_y_probs(m, force=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
