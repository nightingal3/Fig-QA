{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "openai.api_key = open(\"openai_api.key\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(sent):\n",
    "    if not sent.endswith(\".\") or sent.endswith(\"!\"):  # finish with period\n",
    "        sent += '.'\n",
    "    if not sent[0].isupper():  # start with a capital letter\n",
    "        sent = sent[0].upper() + sent[1:]\n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_csv = [['prompt', 'completion']]\n",
    "for i, line in df.iterrows():\n",
    "    prompt = proc(line['startphrase']) + ' -> '\n",
    "    completion = proc(line[f'ending{line[\"labels\"]+1}'])\n",
    "    intermediate_csv.append([prompt, completion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(intermediate_csv).to_csv(\"data/finetune_train.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Based on your file extension, your file is formatted as a CSV file\n",
      "- Your file contains 1458 prompt-completion pairs\n",
      "- All prompts end with suffix `. -> `\n",
      "- All completions end with suffix `.`\n",
      "  WARNING: Some of your completions contain the suffix `.` more than once. We suggest that you review your completions and add a unique ending\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: ^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f data/finetune_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai api fine_tunes.create -t data/finetune_train_prepared.jsonl  -m ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADA_FINETUNED = 'ada:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-03-10-25'\n",
    "BABBAGE_FINETUNED = 'babbage:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-04-06-02'\n",
    "CURIE_FINETUNED = 'curie:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-04-35-14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about the spend $$$ on openai API (model ada:ft-user-6qia53bwp385gfq1da9w5yum-2021-11-28-03-10-25)! conitnue? [y/n]y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [07:49<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "split = 'test'\n",
    "df = pd.read_csv(f\"data/{split}.csv\")\n",
    "restart = None\n",
    "\n",
    "\n",
    "model_name = ADA_FINETUNED\n",
    "\n",
    "if restart is None:\n",
    "    json_lines = {}\n",
    "\n",
    "\n",
    "if model_name != 'debug':\n",
    "    response = input(f\"about the spend $$$ on openai API (model {model_name})! conitnue? [y/n]\")\n",
    "    if response.lower() != 'y':\n",
    "        raise Exception(\"Not continuing.\")\n",
    "else:\n",
    "    print('just debugging. this is free.')\n",
    "\n",
    "    \n",
    "for i, line in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    if restart is not None and i < restart: continue\n",
    "        \n",
    "    start = line['startphrase']\n",
    "    end1 = line['ending1']\n",
    "    end2 = line['ending2']\n",
    "    res_two_endings = []\n",
    "    for j, prompt in enumerate((\n",
    "        proc(start)+' '+proc(end1),\n",
    "        proc(start)+' '+proc(end2),\n",
    "    )):\n",
    "        if model_name == 'debug':\n",
    "            res = debug_res\n",
    "        else:\n",
    "            completion = openai.Completion.create(model=model_name, prompt=prompt,\n",
    "                                                      max_tokens=0,\n",
    "                                                      temperature=0.0,\n",
    "                                                      logprobs=0,\n",
    "                                                      echo=True,\n",
    "                                                      n=1)\n",
    "            logprobs = completion['choices'][0]['logprobs']\n",
    "            res = {k: logprobs[k] for k in ('token_logprobs', 'tokens')}\n",
    "        res_two_endings.append(res)\n",
    "        if model_name != 'debug':\n",
    "            time.sleep(0.05)  # to prevent RateLimitError\n",
    "    json_lines[f\"{line.get('qid', i)}_{line['labels']}\"] = res_two_endings\n",
    "\n",
    "\n",
    "fname = f\"{split}_logprobs_{model_name}.json\"\n",
    "with open(fname, 'w') as f:\n",
    "    f.write('')\n",
    "\n",
    "with open(fname, 'a') as f:\n",
    "    json.dump(json_lines, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_of_ending(token_logprobs, tokens):\n",
    "    logprob_sum = 0\n",
    "    for count, (lp, t) in enumerate(zip(token_logprobs[::-1], tokens[::-1])):\n",
    "        if count > 0 and t.endswith('.'):\n",
    "            break\n",
    "        logprob_sum += lp\n",
    "    return logprob_sum / count\n",
    "\n",
    "\n",
    "def calculate_accuracy(fname):\n",
    "    with open(fname) as f:\n",
    "        logprobs = json.load(f)\n",
    "\n",
    "    correct = 0\n",
    "    for qid_label, (end1, end2) in logprobs.items():\n",
    "        end1_prob = prob_of_ending(end1['token_logprobs'], end1['tokens'])\n",
    "        end2_prob = prob_of_ending(end2['token_logprobs'], end2['tokens'])\n",
    "        label = int(qid_label[-1])\n",
    "        if (label == 0 and end1_prob > end2_prob) or (label==1 and end1_prob < end2_prob):\n",
    "            correct += 1\n",
    "\n",
    "    print(f\"correct: {correct}/{len(logprobs)} = {correct/len(logprobs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 794/1094 = 0.7257769652650823\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(f\"dev_logprobs_{ADA_FINETUNED}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 832/1094 = 0.7605118829981719\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(f\"dev_logprobs_{BABBAGE_FINETUNED}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 866/1094 = 0.7915904936014625\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(f\"dev_logprobs_{CURIE_FINETUNED}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 792/1145 = 0.6917030567685589\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(f\"test_logprobs_{ADA_FINETUNED}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 847/1145 = 0.7397379912663755\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(f\"test_logprobs_{BABBAGE_FINETUNED}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 905/1145 = 0.7903930131004366\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(f\"test_logprobs_{CURIE_FINETUNED}.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
